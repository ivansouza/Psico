<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Local - WebGPU Mobile</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .dot-pulse { animation: pulse 1.5s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 0.4; } 50% { opacity: 1; } }
        #chat-container::-webkit-scrollbar { width: 6px; }
        #chat-container::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 10px; }
    </style>
</head>
<body class="bg-slate-50 h-screen flex flex-col font-sans">

    <!-- Header -->
    <header class="bg-white border-b p-4 flex justify-between items-center shadow-sm">
        <div>
            <h1 class="font-bold text-slate-800 text-lg">Qwen 2.5 (1.5B)</h1>
            <p id="status-text" class="text-xs text-slate-500 italic font-medium">Verificando suporte...</p>
        </div>
        <div id="gpu-badge" class="px-2 py-1 rounded text-[10px] font-bold uppercase tracking-wider bg-slate-200 text-slate-600">
            OFFLINE
        </div>
    </header>

    <!-- Chat Area -->
    <main id="chat-container" class="flex-1 overflow-y-auto p-4 space-y-4 flex flex-col">
        <div class="bg-blue-50 border border-blue-100 p-3 rounded-lg text-sm text-blue-800">
            <strong>Nota:</strong> Como o modelo Liquid LFM2 ainda não é suportado pelo motor do navegador, estamos usando o <strong>Qwen 2.5 1.5B</strong>, que tem o mesmo tamanho e roda perfeitamente via WebGPU.
        </div>
    </main>

    <!-- Loading Overlay -->
    <div id="loading-overlay" class="hidden fixed inset-0 bg-white/90 z-50 flex flex-col items-center justify-center p-6 text-center">
        <div class="w-16 h-16 border-4 border-blue-600 border-t-transparent rounded-full animate-spin mb-4"></div>
        <h2 class="text-xl font-bold text-slate-800 mb-2">Carregando Cérebro...</h2>
        <div class="w-full max-w-xs bg-slate-200 h-2 rounded-full overflow-hidden">
            <div id="progress-bar" class="bg-blue-600 h-full w-0 transition-all duration-300"></div>
        </div>
        <p id="progress-text" class="text-sm text-slate-500 mt-2 italic">Aguardando...</p>
    </div>

    <!-- Input Area -->
    <footer class="p-4 bg-white border-t">
        <div class="flex gap-2">
            <input type="text" id="user-input" placeholder="Aguardando carregamento..." 
                   class="flex-1 border border-slate-300 rounded-full px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:bg-slate-100" 
                   disabled>
            <button id="send-btn" class="bg-blue-600 text-white p-2 rounded-full hover:bg-blue-700 disabled:bg-slate-300 shadow-lg transition-all" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" class="w-6 h-6">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M6 12L3.269 3.126A59.768 59.768 0 0121.485 12 59.77 59.77 0 013.27 20.876L5.999 12zm0 0h7.5" />
                </svg>
            </button>
        </div>
    </footer>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.0.0-alpha.19';

        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const statusText = document.getElementById('status-text');
        const gpuBadge = document.getElementById('gpu-badge');
        const loadingOverlay = document.getElementById('loading-overlay');
        const progressBar = document.getElementById('progress-bar');
        const progressText = document.getElementById('progress-text');

        let generator = null;

        async function init() {
            if (!navigator.gpu) {
                statusText.innerText = "WebGPU não suportado!";
                return;
            }

            gpuBadge.innerText = "WebGPU PRONTO";
            gpuBadge.classList.replace('bg-slate-200', 'bg-green-100');
            gpuBadge.classList.replace('text-slate-600', 'text-green-700');
            
            const loadBtn = document.createElement('button');
            loadBtn.innerText = "Baixar Modelo (950MB)";
            loadBtn.className = "w-full py-4 bg-blue-600 text-white rounded-xl font-bold shadow-lg mb-4";
            loadBtn.onclick = startLoading;
            chatContainer.appendChild(loadBtn);
        }

        async function startLoading() {
            loadingOverlay.classList.remove('hidden');
            try {
                // Qwen 2.5 é o sucessor espiritual e funciona nativamente com transformers.js v3
                const modelId = 'onnx-community/Qwen2.5-1.5B-Instruct-ONNX';
                
                generator = await pipeline('text-generation', modelId, {
                    device: 'webgpu',
                    dtype: 'q4', // Quantização crucial para mobile
                    progress_callback: (data) => {
                        if (data.status === 'progress') {
                            progressBar.style.width = `${data.progress}%`;
                            progressText.innerText = `Baixando ${data.file.split('/').pop()}: ${Math.round(data.progress)}%`;
                        }
                    }
                });

                loadingOverlay.classList.add('hidden');
                statusText.innerText = "Pronto para conversar";
                userInput.disabled = false;
                userInput.placeholder = "Diga olá...";
                sendBtn.disabled = false;
                
                // Limpar botões antigos
                chatContainer.innerHTML = '';
                addMessage("Sistema", "Conectado à GPU local. Pode começar!", "bg-slate-100");
                
            } catch (err) {
                alert("Erro ao carregar: " + err.message);
                console.error(err);
                loadingOverlay.classList.add('hidden');
            }
        }

        function addMessage(sender, text, classes = "") {
            const msgDiv = document.createElement('div');
            msgDiv.className = `p-3 rounded-2xl max-w-[90%] ${sender === 'Você' ? 'bg-blue-600 text-white self-end' : 'bg-white border border-slate-200 text-slate-800 self-start'} ${classes}`;
            msgDiv.innerHTML = `<p class="text-[10px] uppercase font-bold mb-1 opacity-70">${sender}</p><p class="text-sm">${text}</p>`;
            chatContainer.appendChild(msgDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return msgDiv;
        }

        async function chat() {
            const text = userInput.value.trim();
            if (!text || !generator) return;

            userInput.value = '';
            addMessage("Você", text);
            
            const aiMsg = addMessage("AI", "Pensando...", "dot-pulse italic");
            
            try {
                const messages = [{ role: "user", content: text }];
                const output = await generator(messages, { 
                    max_new_tokens: 128,
                    temperature: 0.7 
                });
                
                const response = output[0].generated_text.at(-1).content;
                aiMsg.innerHTML = `<p class="text-[10px] uppercase font-bold mb-1 opacity-70">AI</p><p class="text-sm">${response}</p>`;
                aiMsg.classList.remove('dot-pulse', 'italic');
            } catch (e) {
                aiMsg.innerText = "Erro: " + e.message;
            }
        }

        sendBtn.onclick = chat;
        userInput.onkeypress = (e) => e.key === 'Enter' && chat();

        init();
    </script>
</body>
</html>

