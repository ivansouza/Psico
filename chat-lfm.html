<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Liquid LFM 2.5 - WebGPU Mobile</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .dot-pulse { animation: pulse 1.5s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 0.4; } 50% { opacity: 1; } }
        #chat-container::-webkit-scrollbar { width: 6px; }
        #chat-container::-webkit-scrollbar-thumb { background: #cbd5e1; border-radius: 10px; }
    </style>
</head>
<body class="bg-slate-50 h-screen flex flex-col font-sans">

    <!-- Header -->
    <header class="bg-white border-b p-4 flex justify-between items-center shadow-sm">
        <div>
            <h1 class="font-bold text-slate-800 text-lg">Liquid LFM 2.5</h1>
            <p id="status-text" class="text-xs text-slate-500 italic font-medium">Verificando WebGPU...</p>
        </div>
        <div id="gpu-badge" class="px-2 py-1 rounded text-[10px] font-bold uppercase tracking-wider bg-slate-200 text-slate-600">
            OFFLINE
        </div>
    </header>

    <!-- Chat Area -->
    <main id="chat-container" class="flex-1 overflow-y-auto p-4 space-y-4">
        <div class="bg-blue-50 border border-blue-100 p-3 rounded-lg text-sm text-blue-800">
            <strong>Dica:</strong> O primeiro carregamento baixará ~800MB do modelo. Recomendamos o uso de Wi-Fi. O modelo rodará 100% privado no seu celular.
        </div>
    </main>

    <!-- Progress Overlay (Only during load) -->
    <div id="loading-overlay" class="hidden fixed inset-0 bg-white/90 z-50 flex flex-col items-center justify-center p-6 text-center">
        <div class="w-16 h-16 border-4 border-blue-600 border-t-transparent rounded-full animate-spin mb-4"></div>
        <h2 class="text-xl font-bold text-slate-800 mb-2">Baixando Inteligência...</h2>
        <div class="w-full max-w-xs bg-slate-200 h-2 rounded-full overflow-hidden">
            <div id="progress-bar" class="bg-blue-600 h-full w-0 transition-all duration-300"></div>
        </div>
        <p id="progress-text" class="text-sm text-slate-500 mt-2 italic">Preparando arquivos...</p>
    </div>

    <!-- Input Area -->
    <footer class="p-4 bg-white border-t">
        <div class="flex gap-2">
            <input type="text" id="user-input" placeholder="Digite sua mensagem..." 
                   class="flex-1 border border-slate-300 rounded-full px-4 py-2 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:bg-slate-100" 
                   disabled>
            <button id="send-btn" class="bg-blue-600 text-white p-2 rounded-full hover:bg-blue-700 disabled:bg-slate-300 shadow-lg transition-all" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" class="w-6 h-6">
                    <path stroke-linecap="round" stroke-linejoin="round" d="M6 12L3.269 3.126A59.768 59.768 0 0121.485 12 59.77 59.77 0 013.27 20.876L5.999 12zm0 0h7.5" />
                </svg>
            </button>
        </div>
        <p class="text-[10px] text-center text-slate-400 mt-2 uppercase tracking-widest">Processamento Local via WebGPU</p>
    </footer>

    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.2.1';

        // Configuração para usar WebGPU
        env.allowLocalModels = false;
        
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const statusText = document.getElementById('status-text');
        const gpuBadge = document.getElementById('gpu-badge');
        const loadingOverlay = document.getElementById('loading-overlay');
        const progressBar = document.getElementById('progress-bar');
        const progressText = document.getElementById('progress-text');

        let generator = null;

        // 1. Verificar WebGPU
        async function checkWebGPU() {
            if (!navigator.gpu) {
                statusText.innerText = "WebGPU não suportado neste navegador.";
                statusText.className = "text-xs text-red-500 font-bold";
                return false;
            }
            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (!adapter) throw new Error();
                gpuBadge.innerText = "WebGPU Ativo";
                gpuBadge.className = "px-2 py-1 rounded text-[10px] font-bold uppercase bg-green-100 text-green-700";
                statusText.innerText = "Clique para carregar o modelo";
                userInput.disabled = false;
                userInput.placeholder = "Clique em carregar primeiro...";
                addMessage("Sistema", "Seu dispositivo suporta WebGPU! Clique no botão abaixo para baixar o modelo LFM2.5 (aprox. 800MB).", "bg-green-50 text-green-800");
                
                // Botão de ativação manual (bom para mobile economizar dados)
                const loadBtn = document.createElement('button');
                loadBtn.innerText = "Carregar Modelo LFM2.5 (800MB)";
                loadBtn.className = "w-full py-3 bg-blue-600 text-white rounded-lg font-bold shadow-md mt-2";
                loadBtn.onclick = () => initModel();
                chatContainer.appendChild(loadBtn);
            } catch (e) {
                statusText.innerText = "WebGPU disponível, mas falhou ao iniciar.";
                return false;
            }
        }

        // 2. Inicializar Modelo
        async function initModel() {
            loadingOverlay.classList.remove('hidden');
            try {
                // LiquidAI LFM2.5 1.2B Instruct (Quantizado para Q4)
                // Usamos o repo que contém os arquivos ONNX compatíveis com transformers.js v3
                const modelId = 'LiquidAI/LFM2.5-1.2B-Instruct';
                
                generator = await pipeline('text-generation', modelId, {
                    device: 'webgpu',
                    dtype: 'q4', // Quantização 4-bit para caber no mobile
                    progress_callback: (data) => {
                        if (data.status === 'progress') {
                            const p = Math.round(data.progress);
                            progressBar.style.width = `${p}%`;
                            progressText.innerText = `Baixando ${data.file}: ${p}%`;
                        }
                    }
                });

                loadingOverlay.classList.add('hidden');
                statusText.innerText = "Modelo Carregado e Pronto";
                userInput.disabled = false;
                userInput.placeholder = "Pergunte algo ao LFM...";
                sendBtn.disabled = false;
                addMessage("Sistema", "Modelo carregado com sucesso! O processamento está ocorrendo totalmente no seu celular.", "bg-slate-100 text-slate-600");
                
                // Remove o botão de carga
                const btns = chatContainer.querySelectorAll('button');
                btns.forEach(b => b.remove());

            } catch (err) {
                loadingOverlay.innerHTML = `<div class="p-4 bg-red-100 text-red-700 rounded-lg">Erro ao carregar: ${err.message}<br>Tente recarregar a página.</div>`;
                console.error(err);
            }
        }

        // 3. Gerenciar Mensagens
        function addMessage(sender, text, classes = "") {
            const msgDiv = document.createElement('div');
            msgDiv.className = `p-3 rounded-2xl max-w-[85%] ${sender === 'Você' ? 'bg-blue-600 text-white self-end ml-auto' : 'bg-white border border-slate-200 text-slate-800 self-start'} ${classes}`;
            msgDiv.innerHTML = `<p class="text-[10px] opacity-70 mb-1 font-bold uppercase tracking-tighter">${sender}</p><p class="text-sm leading-relaxed">${text.replace(/\n/g, '<br>')}</p>`;
            chatContainer.appendChild(msgDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
            return msgDiv;
        }

        // 4. Fluxo de Chat
        async function handleChat() {
            const prompt = userInput.value.trim();
            if (!prompt || !generator) return;

            userInput.value = '';
            addMessage("Você", prompt);
            
            const aiMsgDiv = addMessage("LFM", "Pensando...", "dot-pulse italic");
            
            try {
                // Template de chat padrão Instruct da Liquid
                const messages = [
                    { role: "user", content: prompt }
                ];

                const output = await generator(messages, {
                    max_new_tokens: 256,
                    temperature: 0.7,
                    do_sample: true,
                    top_p: 0.9,
                });

                const reply = output[0].generated_text.at(-1).content;
                aiMsgDiv.innerHTML = `<p class="text-[10px] opacity-70 mb-1 font-bold uppercase tracking-tighter">LFM</p><p class="text-sm leading-relaxed">${reply.replace(/\n/g, '<br>')}</p>`;
                aiMsgDiv.classList.remove('dot-pulse', 'italic');

            } catch (err) {
                aiMsgDiv.innerText = "Erro ao gerar resposta: " + err.message;
            }
        }

        sendBtn.onclick = handleChat;
        userInput.onkeypress = (e) => { if(e.key === 'Enter') handleChat(); };

        window.onload = checkWebGPU;
    </script>
</body>
</html>

